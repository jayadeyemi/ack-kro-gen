{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "RLfLElyiAJBH"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import soundfile as sf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYgmFvNZAJBI",
        "outputId": "38de0fbf-ae9a-4638-8503-546bec86c8b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-30.21952+9.251362j) (21.528316-6.439366j) complex64 (513, 2459)\n",
            "(-30.195765+9.228826j) (21.51682-6.52095j) complex64 (513, 2459)\n",
            "(-21.403784-3.3156915j) (22.47935+4.4695153j) complex64 (513, 142)\n",
            "(-21.564178-3.344126j) (22.465538+4.424191j) complex64 (513, 142)\n",
            "(-10.3424015+1.1153554j) (10.666173+1.1317672j) complex64 (513, 380)\n",
            "X_train shape: (2459, 513)\n",
            "Y_train shape: (2459, 513)\n",
            "X_test shape: (142, 513)\n",
            "Y_test shape: (142, 513)\n",
            "X_input shape: (380, 513)\n",
            "X Shape: (513, 2459)\n",
            "S Shape: (513, 2459)\n",
            "TN Shape: (513, 142)\n",
            "T Shape: (513, 142)\n",
            "I Shape: (513, 380)\n"
          ]
        }
      ],
      "source": [
        "# Load clean and noisy audio files\n",
        "s, sr_s = librosa.load('train_clean_male.wav', sr=None)\n",
        "sn, sr_sn = librosa.load('train_dirty_male.wav', sr=None)\n",
        "t, sr_t = librosa.load('test_s_01.wav', sr=None)\n",
        "tn, sr_tn = librosa.load('test_x_01.wav', sr=None)\n",
        "i, sr_i = librosa.load('test_x_02.wav', sr=None)\n",
        "\n",
        "# Set the STFT parameters\n",
        "n_fft = 1024\n",
        "hop_length = 512\n",
        "\n",
        "# Compute the STFT and magnitude spectrograms\n",
        "X = librosa.stft(sn, n_fft=n_fft, hop_length=hop_length)\n",
        "S = librosa.stft(s, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "TN = librosa.stft(tn, n_fft=n_fft, hop_length=hop_length)\n",
        "T = librosa.stft(t, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "I = librosa.stft(i, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "# print the min, max of the arrays and the dtype\n",
        "print(np.min(X), np.max(X), X.dtype, X.shape)\n",
        "print(np.min(S), np.max(S), S.dtype, S.shape)\n",
        "\n",
        "print(np.min(TN), np.max(TN), TN.dtype, TN.shape)\n",
        "print(np.min(T), np.max(T), T.dtype, T.shape)\n",
        "\n",
        "print(np.min(I), np.max(I), I.dtype, I.shape)\n",
        "\n",
        "\n",
        "# Transpose the magnitude spectrograms\n",
        "X_train = X.T\n",
        "Y_train = S.T\n",
        "X_test = TN.T\n",
        "Y_test = T.T\n",
        "X_input = I.T\n",
        "\n",
        "\n",
        "# print the shape of the magnitude spectrograms\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('Y_train shape:', Y_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "print('Y_test shape:', Y_test.shape)\n",
        "print('X_input shape:', X_input.shape)\n",
        "\n",
        "print('X Shape:', X.shape)\n",
        "print('S Shape:', S.shape)\n",
        "print('TN Shape:', TN.shape)\n",
        "print('T Shape:', T.shape)\n",
        "print('I Shape:', I.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def snr_metric(y_true, y_pred):\n",
        "    # Compute the signal power (sum of squares of the true signal)\n",
        "    signal_power = tf.reduce_sum(tf.square(y_true), axis=-1)\n",
        "\n",
        "    # Compute the noise power (sum of squares of the difference between true and predicted signal)\n",
        "    noise_power = tf.reduce_sum(tf.square(y_true - y_pred), axis=-1)\n",
        "\n",
        "    # Add a small epsilon to avoid division by zero\n",
        "    epsilon = 1e-20\n",
        "\n",
        "    # Calculate the SNR\n",
        "    snr = 10 * tf.math.log(signal_power / (noise_power + epsilon)) / tf.math.log(10.0)\n",
        "\n",
        "    # Define a reasonable SNR range to map to a 0-100% scale\n",
        "    # SNR in practice could be in a range like -20 dB to +40 dB\n",
        "    snr_min = -20.0  # Poor signal\n",
        "    snr_max = 40.0   # Excellent signal\n",
        "\n",
        "    # Clip SNR to this range to avoid extreme values skewing the result\n",
        "    snr_clipped = tf.clip_by_value(snr, snr_min, snr_max)\n",
        "\n",
        "    # Normalize SNR to a 0-100% scale\n",
        "    snr_percentage = (snr_clipped - snr_min) / (snr_max - snr_min) * 100.0\n",
        "\n",
        "    # Return the average percentage score across all samples\n",
        "    return tf.reduce_mean(snr_percentage)\n"
      ],
      "metadata": {
        "id": "BGooWirh3Z-j"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "SKVP15SPAJBJ"
      },
      "outputs": [],
      "source": [
        "# Define the speech enhancement model\n",
        "def train_speech_enhancement_model(X_train_raw, Y_train_raw, X_test_raw, Y_test_raw, X_input_raw,\n",
        "                                   layers=[512, 256, 128], activations=['relu', 'relu', 'relu'],\n",
        "                                   output_activation='relu',\n",
        "                                   epochs=50, optimizer='adam'):\n",
        "\n",
        "    # Take the absolute value of the magnitude spectrograms\n",
        "    Y_train_magnitude = np.abs(Y_train_raw)\n",
        "    X_train_magnitude = np.abs(X_train_raw)\n",
        "    Y_test_magnitude = np.abs(Y_test_raw)\n",
        "    X_test_magnitude = np.abs(X_test_raw)\n",
        "    X_input_magnitude = np.abs(X_input_raw)\n",
        "\n",
        "    print('X_train :', X_train.shape, X_train.dtype)\n",
        "    print('Y_train :', Y_train.shape, Y_train.dtype)\n",
        "    print('X_test :', X_test.shape, X_test.dtype)\n",
        "    print('Y_test :', Y_test.shape, Y_test.dtype)\n",
        "    print('X_input :', X_input.shape, X_input.dtype)\n",
        "\n",
        "    # normalize the magnitude spectrograms using standard scaler\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_magnitude)\n",
        "    Y_train_scaled = scaler.transform(Y_train_magnitude)\n",
        "    X_test_scaled = scaler.transform(X_test_magnitude)\n",
        "    Y_test_scaled = scaler.transform(Y_test_magnitude)\n",
        "    X_input_scaled = scaler.transform(X_input_magnitude)\n",
        "\n",
        "    # Define the SNR loss function\n",
        "    def snr_loss_fn(y_true, y_pred):\n",
        "        # Compute the signal power (sum of squares of the true signal)\n",
        "        signal_power = tf.reduce_sum(tf.square(y_true), axis=-1)\n",
        "        noise_power = tf.reduce_sum(tf.square(y_true - y_pred), axis=-1)\n",
        "        epsilon = 1e-20\n",
        "        snr = 10 * tf.math.log(signal_power / (noise_power + epsilon)) / tf.math.log(10.0)\n",
        "        return -tf.reduce_mean(snr)\n",
        "\n",
        "\n",
        "    def snr_metric(y_true, y_pred):\n",
        "        signal_power = tf.reduce_mean(tf.square(y_true))\n",
        "        noise_power = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "        snr = 10.0 * tf.math.log(signal_power / noise_power) / tf.math.log(10.0)\n",
        "        return snr\n",
        "\n",
        "\n",
        "    # Ensure input shape for the model\n",
        "    input_shape = 513\n",
        "    print(X_train.shape[1])\n",
        "    # Build the model\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(shape=(input_shape,)))\n",
        "    for units, activation in zip(layers, activations):\n",
        "        model.add(tf.keras.layers.Dense(units, activation=activation))\n",
        "    model.add(tf.keras.layers.Dense(input_shape, activation=output_activation))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=SGD(learning_rate=0.1), loss=snr_loss_fn, metrics=[snr_metric])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train_scaled, Y_train_scaled, epochs=epochs, validation_data=(X_test_scaled, Y_test_scaled))\n",
        "\n",
        "    # Test the model on the test dataset\n",
        "    X_output = model.predict(X_test_scaled)\n",
        "\n",
        "    # Inverse transform the scaled magnitude spectrograms\n",
        "    Y_output_magnitude = scaler.inverse_transform(X_output)\n",
        "\n",
        "    # Compute the SNR on the test dataset\n",
        "    signal_power = np.sum(np.square(Y_test_magnitude), axis=-1)\n",
        "    noise_power = np.sum(np.square(Y_test_magnitude - Y_output_magnitude), axis=-1)\n",
        "    snr = np.mean(10 * np.log10(signal_power / noise_power))\n",
        "\n",
        "    # recapture the original phase information\n",
        "    Y_output = Y_output_magnitude * Y_test_raw / Y_test_magnitude\n",
        "\n",
        "    # Inverse STFT to obtain the enhanced audio\n",
        "    Y_output = librosa.istft(Y_output.T, hop_length=hop_length)\n",
        "\n",
        "    # Return the model and prediction results\n",
        "    return model, Y_output, history, snr\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # def plot_spectrograms(original, noisy, enhanced, sr, hop_length):\n",
        "    #     fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
        "\n",
        "    #     # Plot original clean audio spectrogram\n",
        "    #     ax = axes[0]\n",
        "    #     S_dB = librosa.amplitude_to_db(np.abs(original), ref=np.max)\n",
        "    #     img = librosa.display.specshow(S_dB, sr=sr, hop_length=hop_length, x_axis='time', y_axis='log', ax=ax)\n",
        "    #     ax.set_title('Original Clean Spectrogram')\n",
        "    #     fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
        "\n",
        "    #     # Plot noisy audio spectrogram\n",
        "    #     ax = axes[1]\n",
        "    #     X_dB = librosa.amplitude_to_db(np.abs(noisy), ref=np.max)\n",
        "    #     img = librosa.display.specshow(X_dB, sr=sr, hop_length=hop_length, x_axis='time', y_axis='log', ax=ax)\n",
        "    #     ax.set_title('Noisy Spectrogram')\n",
        "    #     fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
        "\n",
        "    #     # Plot enhanced audio spectrogram\n",
        "    #     ax = axes[2]\n",
        "    #     Y_dB = librosa.amplitude_to_db(np.abs(enhanced), ref=np.max)\n",
        "    #     img = librosa.display.specshow(Y_dB, sr=sr, hop_length=hop_length, x_axis='time', y_axis='log', ax=ax)\n",
        "    #     ax.set_title('Enhanced Spectrogram')\n",
        "    #     fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
        "\n",
        "    #     plt.tight_layout()\n",
        "    #     plt.show()\n",
        "    #     # Plot original clean audio spectrogram\n",
        "    # plot_spectrograms(T, TN, Y_output, sr_t, hop_length)\n"
      ],
      "metadata": {
        "id": "Dao1fWhh10T3"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "UsH1pGumAJBJ"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the grid search function\n",
        "def grid_search_snr(X_train, Y_train, X_test, Y_test, X_input, param_grid):\n",
        "\n",
        "    param_combinations = list(itertools.product(*param_grid.values()))\n",
        "    histories = []\n",
        "    Y_outputs = []\n",
        "    models = []\n",
        "    snrs = []\n",
        "\n",
        "    # Perform grid search\n",
        "    for param_combination in param_combinations:\n",
        "        params = {key: value for key, value in zip(param_grid.keys(), param_combination)}\n",
        "\n",
        "        print(f\"Training with parameters: {params}\")  # Print the current parameter combination\n",
        "\n",
        "        # Train the model with the current parameter combination\n",
        "        model, Y_output, history, snr = train_speech_enhancement_model(\n",
        "            X_train, Y_train, X_test, Y_test, X_input,\n",
        "            layers=params['layers'],\n",
        "            activations=params['activations'],\n",
        "            output_activation=params['output_activation'],\n",
        "            epochs=params['epochs'],\n",
        "            optimizer=params['optimizer']\n",
        "        )\n",
        "\n",
        "        # Store the result\n",
        "        histories.append({\n",
        "            'params': params,\n",
        "            'history': history\n",
        "        })\n",
        "\n",
        "        Y_outputs.append({\n",
        "            'params': params,\n",
        "            'Y_output': Y_output,\n",
        "            'snr': snr\n",
        "        })\n",
        "\n",
        "        models.append({\n",
        "            'params': params,\n",
        "            'model': model\n",
        "        })\n",
        "\n",
        "        snrs.append({\n",
        "            'params': params,\n",
        "            'snr': snr\n",
        "        })\n",
        "\n",
        "    return models, Y_outputs, histories, snrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7ShMlRrDdUD",
        "outputId": "86837e92-83d1-4f7f-bff3-07c8f198c250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import soundfile as sf\n",
        "import os\n",
        "\n",
        "# Mount the Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def save_y_outputs(Y_outputs, sr):\n",
        "    # Define the path in Google Drive\n",
        "    drive_path = '/content/drive/My Drive/Colab_Audio_Files'\n",
        "    os.makedirs(drive_path, exist_ok=True)  # Ensure the directory exists\n",
        "\n",
        "    # Loop through each output dict in Y_outputs\n",
        "    for idx, output_dict in enumerate(Y_outputs):\n",
        "        params = output_dict['params']  # Extract parameters\n",
        "        Y_output = output_dict['Y_output']  # Extract audio data\n",
        "\n",
        "        snr = output_dict['snr']  # Extract SNR\n",
        "\n",
        "        # Construct the filename safely\n",
        "        filename = f\"{params['layers']}_{params['activations']}_{params['epochs']}_[{snr}].wav\"\n",
        "\n",
        "        # Define the full path for the file\n",
        "        full_path = os.path.join(drive_path, filename)\n",
        "\n",
        "        # Save the audio file\n",
        "        sf.write(full_path, Y_output, sr)\n",
        "\n",
        "        # Print confirmation\n",
        "        print(f\"Saved {full_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "lpcz8br4AJBK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_losses(histories, snrs):\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 15))  # Vertically stacked subplots\n",
        "\n",
        "    for history_info, snr_info in zip(histories, snrs):\n",
        "        params = history_info['params']\n",
        "        snr = snr_info['snr']\n",
        "        history = history_info['history']\n",
        "\n",
        "        label = f\"Params: {params}, SNR: {snr:.2f} dB\"\n",
        "\n",
        "        ax1.plot(history.history['val_loss'], label=label)\n",
        "        ax2.plot(history.history['val_snr_metric'], label=label)\n",
        "\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.set_title('Validation Loss over Epochs')\n",
        "\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('SNR (dB)')\n",
        "    ax2.set_title('Validation SNR over Epochs')\n",
        "\n",
        "    # Position the legends beneath each plot\n",
        "    ax1.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15))\n",
        "    ax2.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15))\n",
        "\n",
        "    # Adjust the layout for more space between subplots\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(bottom=0.2, hspace=2)  # Increase hspace for more vertical space between subplots\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "_6fD4UrFgoJU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def snr_table(snrs):\n",
        "\n",
        "    # print the SNR values in a dataframe\n",
        "    snr_df = pd.DataFrame(snrs)\n",
        "    snr_df = snr_df.sort_values(by='snr', ascending=False)\n",
        "    print(snr_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxnZnjNKuBNx"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "quQ7rdC6jNsg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'layers': [[128, 64, 32, 64]],\n",
        "    'activations': [['tanh', 'tanh', 'tanh', 'tanh'], ['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid'], ['relu', 'relu', 'relu', 'relu'], ['leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu'], ['elu', 'elu', 'elu', 'elu']],\n",
        "    'output_activation': ['relu', 'softplus', 'exponential', 'sigmoid'],\n",
        "    'epochs': [100],  # Shorter epochs for grid search\n",
        "    'optimizer': ['adam']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euQCP_GcjNjn",
        "outputId": "92b42067-0aae-4a75-99c7-a8e105ad9f2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with parameters: {'layers': [128, 64, 32, 64], 'activations': ['tanh', 'tanh', 'tanh', 'tanh'], 'output_activation': 'relu', 'epochs': 100, 'optimizer': 'adam'}\n",
            "X_train : (2459, 513) complex64\n",
            "Y_train : (2459, 513) complex64\n",
            "X_test : (142, 513) complex64\n",
            "Y_test : (142, 513) complex64\n",
            "X_input : (380, 513) complex64\n",
            "513\n",
            "Epoch 1/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.3257 - snr_metric: -0.1709 - val_loss: 0.0083 - val_snr_metric: 0.0034\n",
            "Epoch 2/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0014 - snr_metric: 0.0273 - val_loss: -0.0145 - val_snr_metric: 0.0276\n",
            "Epoch 3/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.0436 - snr_metric: 0.0957 - val_loss: -0.0393 - val_snr_metric: 0.0569\n",
            "Epoch 4/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.0879 - snr_metric: 0.1717 - val_loss: -0.0639 - val_snr_metric: 0.0880\n",
            "Epoch 5/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.1310 - snr_metric: 0.2453 - val_loss: -0.0861 - val_snr_metric: 0.1162\n",
            "Epoch 6/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.1921 - snr_metric: 0.3258 - val_loss: -0.1137 - val_snr_metric: 0.1499\n",
            "Epoch 7/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.2225 - snr_metric: 0.3904 - val_loss: -0.1406 - val_snr_metric: 0.1825\n",
            "Epoch 8/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.2704 - snr_metric: 0.4880 - val_loss: -0.1664 - val_snr_metric: 0.2089\n",
            "Epoch 9/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.3258 - snr_metric: 0.5598 - val_loss: -0.1955 - val_snr_metric: 0.2337\n",
            "Epoch 10/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.3642 - snr_metric: 0.6172 - val_loss: -0.2219 - val_snr_metric: 0.2668\n",
            "Epoch 11/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.4085 - snr_metric: 0.7061 - val_loss: -0.2445 - val_snr_metric: 0.2911\n",
            "Epoch 12/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.4123 - snr_metric: 0.6974 - val_loss: -0.2636 - val_snr_metric: 0.3109\n",
            "Epoch 13/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.4539 - snr_metric: 0.7848 - val_loss: -0.2831 - val_snr_metric: 0.3303\n",
            "Epoch 14/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.4957 - snr_metric: 0.8311 - val_loss: -0.3153 - val_snr_metric: 0.3710\n",
            "Epoch 15/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.5042 - snr_metric: 0.8702 - val_loss: -0.3323 - val_snr_metric: 0.3877\n",
            "Epoch 16/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.5491 - snr_metric: 0.9277 - val_loss: -0.3556 - val_snr_metric: 0.4103\n",
            "Epoch 17/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.5577 - snr_metric: 0.9639 - val_loss: -0.3835 - val_snr_metric: 0.4495\n",
            "Epoch 18/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.5715 - snr_metric: 0.9970 - val_loss: -0.3982 - val_snr_metric: 0.4615\n",
            "Epoch 19/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6347 - snr_metric: 1.1127 - val_loss: -0.4106 - val_snr_metric: 0.4769\n",
            "Epoch 20/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.6569 - snr_metric: 1.1306 - val_loss: -0.4262 - val_snr_metric: 0.4897\n",
            "Epoch 21/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.6733 - snr_metric: 1.1395 - val_loss: -0.4427 - val_snr_metric: 0.5093\n",
            "Epoch 22/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.6799 - snr_metric: 1.1948 - val_loss: -0.4611 - val_snr_metric: 0.5295\n",
            "Epoch 23/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.7349 - snr_metric: 1.2850 - val_loss: -0.4574 - val_snr_metric: 0.5166\n",
            "Epoch 24/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.7211 - snr_metric: 1.2552 - val_loss: -0.4873 - val_snr_metric: 0.5611\n",
            "Epoch 25/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.7276 - snr_metric: 1.2520 - val_loss: -0.4907 - val_snr_metric: 0.5500\n",
            "Epoch 26/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.7670 - snr_metric: 1.3169 - val_loss: -0.5173 - val_snr_metric: 0.5998\n",
            "Epoch 27/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.7791 - snr_metric: 1.3790 - val_loss: -0.5331 - val_snr_metric: 0.6202\n",
            "Epoch 28/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.7407 - snr_metric: 1.3146 - val_loss: -0.5428 - val_snr_metric: 0.6073\n",
            "Epoch 29/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.7977 - snr_metric: 1.3943 - val_loss: -0.5585 - val_snr_metric: 0.6360\n",
            "Epoch 30/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.8558 - snr_metric: 1.4826 - val_loss: -0.5528 - val_snr_metric: 0.6220\n",
            "Epoch 31/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.8565 - snr_metric: 1.4751 - val_loss: -0.5824 - val_snr_metric: 0.6582\n",
            "Epoch 32/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.8595 - snr_metric: 1.4524 - val_loss: -0.5825 - val_snr_metric: 0.6460\n",
            "Epoch 33/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.8917 - snr_metric: 1.5200 - val_loss: -0.5856 - val_snr_metric: 0.6587\n",
            "Epoch 34/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.8964 - snr_metric: 1.5375 - val_loss: -0.5862 - val_snr_metric: 0.6615\n",
            "Epoch 35/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.9209 - snr_metric: 1.5564 - val_loss: -0.5965 - val_snr_metric: 0.6759\n",
            "Epoch 36/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.9370 - snr_metric: 1.6411 - val_loss: -0.6037 - val_snr_metric: 0.6865\n",
            "Epoch 37/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.9239 - snr_metric: 1.5713 - val_loss: -0.6047 - val_snr_metric: 0.6811\n",
            "Epoch 38/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -0.9555 - snr_metric: 1.6305 - val_loss: -0.6320 - val_snr_metric: 0.7201\n",
            "Epoch 39/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.9518 - snr_metric: 1.6136 - val_loss: -0.6082 - val_snr_metric: 0.6824\n",
            "Epoch 40/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.9582 - snr_metric: 1.7015 - val_loss: -0.6154 - val_snr_metric: 0.6691\n",
            "Epoch 41/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.9272 - snr_metric: 1.5542 - val_loss: -0.6345 - val_snr_metric: 0.7086\n",
            "Epoch 42/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.9928 - snr_metric: 1.6755 - val_loss: -0.6428 - val_snr_metric: 0.7329\n",
            "Epoch 43/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.9701 - snr_metric: 1.7063 - val_loss: -0.6601 - val_snr_metric: 0.7568\n",
            "Epoch 44/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1.0202 - snr_metric: 1.7631 - val_loss: -0.6638 - val_snr_metric: 0.7609\n",
            "Epoch 45/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.0294 - snr_metric: 1.7520 - val_loss: -0.6607 - val_snr_metric: 0.7817\n",
            "Epoch 46/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.0420 - snr_metric: 1.7115 - val_loss: -0.6790 - val_snr_metric: 0.7776\n",
            "Epoch 47/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.0621 - snr_metric: 1.7675 - val_loss: -0.6798 - val_snr_metric: 0.7791\n",
            "Epoch 48/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.1030 - snr_metric: 1.8875 - val_loss: -0.6501 - val_snr_metric: 0.7133\n",
            "Epoch 49/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.0852 - snr_metric: 1.8111 - val_loss: -0.6761 - val_snr_metric: 0.7747\n",
            "Epoch 50/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1.1175 - snr_metric: 1.8640 - val_loss: -0.6674 - val_snr_metric: 0.7797\n",
            "Epoch 51/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.0710 - snr_metric: 1.7927 - val_loss: -0.6807 - val_snr_metric: 0.7768\n",
            "Epoch 52/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.0778 - snr_metric: 1.8830 - val_loss: -0.6963 - val_snr_metric: 0.8012\n",
            "Epoch 53/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.1460 - snr_metric: 1.9125 - val_loss: -0.7081 - val_snr_metric: 0.8232\n",
            "Epoch 54/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.1231 - snr_metric: 1.8925 - val_loss: -0.7039 - val_snr_metric: 0.8074\n",
            "Epoch 55/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.1088 - snr_metric: 1.8546 - val_loss: -0.7018 - val_snr_metric: 0.8094\n",
            "Epoch 56/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1.0714 - snr_metric: 1.8262 - val_loss: -0.7083 - val_snr_metric: 0.7892\n",
            "Epoch 57/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.0901 - snr_metric: 1.8488 - val_loss: -0.7165 - val_snr_metric: 0.8161\n",
            "Epoch 58/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.1389 - snr_metric: 1.9358 - val_loss: -0.7265 - val_snr_metric: 0.8368\n",
            "Epoch 59/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -1.1505 - snr_metric: 1.9776 - val_loss: -0.7238 - val_snr_metric: 0.8414\n",
            "Epoch 60/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -1.1338 - snr_metric: 1.8884 - val_loss: -0.7301 - val_snr_metric: 0.8324\n",
            "Epoch 61/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.1380 - snr_metric: 1.9613 - val_loss: -0.7389 - val_snr_metric: 0.8474\n",
            "Epoch 62/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: -1.1913 - snr_metric: 2.0044 - val_loss: -0.7273 - val_snr_metric: 0.8345\n",
            "Epoch 63/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -1.1516 - snr_metric: 1.9249 - val_loss: -0.7378 - val_snr_metric: 0.8543\n",
            "Epoch 64/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1.2051 - snr_metric: 2.0679 - val_loss: -0.7215 - val_snr_metric: 0.8220\n",
            "Epoch 65/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1.2180 - snr_metric: 2.0478 - val_loss: -0.7223 - val_snr_metric: 0.8117\n",
            "Epoch 66/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.2327 - snr_metric: 2.0581 - val_loss: -0.7413 - val_snr_metric: 0.8452\n",
            "Epoch 67/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1.1752 - snr_metric: 1.9627 - val_loss: -0.7557 - val_snr_metric: 0.8733\n",
            "Epoch 68/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.1754 - snr_metric: 2.0877 - val_loss: -0.7475 - val_snr_metric: 0.8395\n",
            "Epoch 69/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.2146 - snr_metric: 2.0291 - val_loss: -0.7585 - val_snr_metric: 0.8822\n",
            "Epoch 70/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.2719 - snr_metric: 2.1103 - val_loss: -0.7449 - val_snr_metric: 0.8617\n",
            "Epoch 71/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.1902 - snr_metric: 2.0455 - val_loss: -0.7582 - val_snr_metric: 0.8801\n",
            "Epoch 72/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1.2331 - snr_metric: 2.0813 - val_loss: -0.7703 - val_snr_metric: 0.8974\n",
            "Epoch 73/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1.2494 - snr_metric: 2.0792 - val_loss: -0.7511 - val_snr_metric: 0.8597\n",
            "Epoch 74/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1.2493 - snr_metric: 2.1212 - val_loss: -0.7661 - val_snr_metric: 0.8868\n",
            "Epoch 75/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1.2582 - snr_metric: 2.1155 - val_loss: -0.7639 - val_snr_metric: 0.8970\n",
            "Epoch 76/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -1.1970 - snr_metric: 2.0704 - val_loss: -0.7632 - val_snr_metric: 0.8748\n",
            "Epoch 77/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -1.2346 - snr_metric: 2.0593 - val_loss: -0.7385 - val_snr_metric: 0.8393\n",
            "Epoch 78/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -1.2406 - snr_metric: 2.0599 - val_loss: -0.7731 - val_snr_metric: 0.9002\n",
            "Epoch 79/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: -1.2584 - snr_metric: 2.1099 - val_loss: -0.7602 - val_snr_metric: 0.8619\n",
            "Epoch 80/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -1.2714 - snr_metric: 2.1776 - val_loss: -0.7831 - val_snr_metric: 0.9118\n",
            "Epoch 81/100\n"
          ]
        }
      ],
      "source": [
        "models, Y_outputs, histories, snrs = grid_search_snr(X_train, Y_train, X_test, Y_test, X_test, param_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBGgFwaJjNZi"
      },
      "outputs": [],
      "source": [
        "save_y_outputs(Y_outputs, sr_tn)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(histories, snrs)\n"
      ],
      "metadata": {
        "id": "Otab9tff--jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "snr_table(snrs)"
      ],
      "metadata": {
        "id": "EK25yCGX9FS9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}